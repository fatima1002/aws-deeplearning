{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breeding Image Classification\n",
    "\n",
    "This notebook lists all the steps that you need to complete the complete this project. You will need to complete all the TODOs in this notebook as well as in the README and the two python scripts included with the starter code.\n",
    "\n",
    "\n",
    "**TODO**: Give a helpful introduction to what this notebook is for. Remember that comments, explanations and good documentation make your project informative and professional.\n",
    "\n",
    "This notebook will develop an image classification model which predicts the dog breed from an image. The code , developed to run on AWS Sagemaker using Pytorch model architecture, will conduct transfer learning using a convolutional neural network (CNN). The CNN architecture we have used in ResNet18. Hyperparamter tuning will be applied to find the best parameters to refine the model, and we will use AWS Debugger and Profiler to understand accuracy and computatinal performance respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting smdebug\n",
      "  Using cached smdebug-1.0.12-py2.py3-none-any.whl (270 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from smdebug) (20.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from smdebug) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from smdebug) (1.20.3)\n",
      "Collecting pyinstrument==3.4.2\n",
      "  Using cached pyinstrument-3.4.2-py2.py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /opt/conda/lib/python3.7/site-packages (from smdebug) (1.20.23)\n",
      "Collecting pyinstrument-cext>=0.2.2\n",
      "  Using cached pyinstrument_cext-0.2.4-cp37-cp37m-manylinux2010_x86_64.whl (20 kB)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.23 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (1.23.23)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->smdebug) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->smdebug) (1.14.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.23->boto3>=1.10.32->smdebug) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.23->boto3>=1.10.32->smdebug) (2.8.1)\n",
      "Installing collected packages: pyinstrument-cext, pyinstrument, smdebug\n",
      "Successfully installed pyinstrument-3.4.2 pyinstrument-cext-0.2.4 smdebug-1.0.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# TODO: Install any packages that you might need\n",
    "# For instance, you will need the smdebug package\n",
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import any packages that you might need\n",
    "# For instance you will need Boto3 and Sagemaker\n",
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.debugger import (\n",
    "    Rule,\n",
    "    DebuggerHookConfig,\n",
    "    rule_configs,\n",
    ")\n",
    "\n",
    "from sagemaker.debugger import ( \n",
    "    ProfilerRule, \n",
    "    ProfilerConfig, \n",
    "    FrameworkProfile\n",
    ")\n",
    "\n",
    "# from io import BytesIO\n",
    "# from zipfile import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Class distrubitions : \n",
    "TODO: Explain what dataset you are using for this project. Maybe even give a small overview of the classes, class distributions etc that can help anyone not familiar with the dataset get a better understand of it.\n",
    "\n",
    "This is a dog classificatoin dataset , further information can be found [*https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip*] There are 133 classes and the dataset is split into three folders - train, validation and test. The dataset split as follows:\n",
    "6680 images for the training set\n",
    "835 images for the validation set\n",
    "836 images for the test set\n",
    "\n",
    "In the following cells we download the data and upload to a S3 bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fetch and upload the data to AWS S3\n",
    "\n",
    "# Command to download and unzip data\n",
    "# !wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "\n",
    "# --2022-01-06 19:50:15--  https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "# Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 3.5.163.157\n",
    "# Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|3.5.163.157|:443... connected.\n",
    "# HTTP request sent, awaiting response... 200 OK\n",
    "# Length: 1132023110 (1.1G) [application/zip]\n",
    "# Saving to: ‘dogImages.zip’\n",
    "\n",
    "# dogImages.zip       100%[===================>]   1.05G  38.8MB/s    in 43s     \n",
    "\n",
    "# 2022-01-06 19:51:01 (24.9 MB/s) - ‘dogImages.zip’ saved [1132023110/1132023110]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip dogImages.zip\n",
    "# Archive:  dogImages.zip\n",
    "#    creating: dogImages/\n",
    "#    creating: dogImages/test/\n",
    "#    creating: dogImages/train/\n",
    "#    creating: dogImages/valid/\n",
    "#    creating: dogImages/test/001.Affenpinscher/\n",
    "#   inflating: dogImages/test/001.Affenpinscher/Affenpinscher_00003.jpg  \n",
    "#   inflating: dogImages/test/001.Affenpinscher/Affenpinscher_00023.jpg  \n",
    "#   inflating: dogImages/test/001.Affenpinscher/Affenpinscher_00036.jpg  \n",
    "#   inflating: dogImages/test/001.Affenpinscher/Affenpinscher_00047.jpg  \n",
    "#   inflating: dogImages/test/001.Affenpinscher/Affenpinscher_00048.jpg  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 cp dogImages 's3://lesson4project/imageproject/' --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "**TODO:** This is the part where you will finetune a pretrained model with hyperparameter tuning. Remember that you have to tune a minimum of two hyperparameters. However you are encouraged to tune more. You are also encouraged to explain why you chose to tune those particular hyperparameters and the ranges.\n",
    "\n",
    "The hyperamaters we chose to tune are :\n",
    "1. learning rate (lr): Controls how much to change the model in response to the loss when the model weights are updated. If too high the weights change too much and we increase error , if too low the model will take a long time to converge.\n",
    "2. batch size : We want the highest batch size that will allow for fast training but also without impacting the loss too greatly.\n",
    "3. epochs: We would like the best model without overfitting the model/ \n",
    "\n",
    "**Note:** You will need to use the `hpo.py` script to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your HP ranges, metrics etc.\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.001, 0.1),\n",
    "    \"batch_size\": CategoricalParameter([64, 128, 256, 512]),\n",
    "    \"epochs\": IntegerParameter(2, 4)\n",
    "}\n",
    "\n",
    "objective_metric_name = \"average test loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"average test loss\", \n",
    "                       \"Regex\": \"average test loss: ([0-9\\\\.]+)\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create estimators for your HPs\n",
    "# bucket = 'lesson4project'\n",
    "# prefix = \"imageproject\"\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"hpo.py\", #training file\n",
    "    role=role, #execution role\n",
    "    py_version='py36',\n",
    "    framework_version=\"1.8\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "os.environ['SM_MODEL_DIR']='s3://lesson4project/imageproject/model/'\n",
    "os.environ['SM_OUTPUT_DATA_DIR']='s3://lesson4project/imageproject/output/'\n",
    "os.environ['SM_CHANNEL_TRAINING']='s3://lesson4project/imageproject/'\n",
    "# TODO: Fit your HP Tuner :  # TODO: Remember to include your data channels\n",
    "tuner.fit({\"training\": 's3://lesson4project/imageproject/'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-01-23 22:22:37 Starting - Preparing the instances for training\n",
      "2022-01-23 22:22:37 Downloading - Downloading input data\n",
      "2022-01-23 22:22:37 Training - Training image download completed. Training in progress.\n",
      "2022-01-23 22:22:37 Uploading - Uploading generated training model\n",
      "2022-01-23 22:22:37 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "# TODO: Get the best estimators and the best HPs\n",
    "best_estimator = tuner.best_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': '\"average test loss\"',\n",
       " 'batch_size': '\"128\"',\n",
       " 'epochs': '3',\n",
       " 'lr': '0.0014267005122579185',\n",
       " 'sagemaker_container_log_level': '20',\n",
       " 'sagemaker_estimator_class_name': '\"PyTorch\"',\n",
       " 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"',\n",
       " 'sagemaker_job_name': '\"pytorch-training-2022-01-23-21-12-44-711\"',\n",
       " 'sagemaker_program': '\"hpo.py\"',\n",
       " 'sagemaker_region': '\"us-east-1\"',\n",
       " 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-758745060942/pytorch-training-2022-01-23-21-12-44-711/source/sourcedir.tar.gz\"'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the hyperparameters of the best trained model\n",
    "best_estimator.hyperparameters()\n",
    "{'_tuning_objective_metric': '\"average test loss\"',\n",
    " 'batch_size': '\"128\"',\n",
    " 'epochs': '3',\n",
    " 'lr': '0.0014267005122579185',\n",
    " 'sagemaker_container_log_level': '20',\n",
    " 'sagemaker_estimator_class_name': '\"PyTorch\"',\n",
    " 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"',\n",
    " 'sagemaker_job_name': '\"pytorch-training-2022-01-23-21-12-44-711\"',\n",
    " 'sagemaker_program': '\"hpo.py\"',\n",
    " 'sagemaker_region': '\"us-east-1\"',\n",
    " 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-758745060942/pytorch-training-2022-01-23-21-12-44-711/source/sourcedir.tar.gz\"'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"batch_size\": int(best_estimator.hyperparameters()['batch_size'].replace('\"', '')), \\\n",
    "                   \"lr\": best_estimator.hyperparameters()['lr'],\n",
    "                   \"epochs\": int(best_estimator.hyperparameters()['epochs'])}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Profiling and Debugging\n",
    "TODO: Using the best hyperparameters, create and finetune a new model\n",
    "\n",
    "**Note:** You will need to use the `train_model.py` script to perform model profiling and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up debugging and profiling rules and hooks\n",
    "hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\"train.save_interval\": \"100\",\n",
    "     \"eval.save_interval\": \"10\"}\n",
    ")\n",
    "\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, \n",
    "    framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")\n",
    "\n",
    "\n",
    "rules = [\n",
    "    # profiler rules\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "    # debugger rules\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and fit an estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train_model.py\",\n",
    "    base_job_name=\"bestmodel\",\n",
    "    role= role ,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    ## Debugger parameters\n",
    "    rules=rules,\n",
    "    debugger_hook_config=hook_config,\n",
    "    # profiler\n",
    "    profiler_config=profiler_config,\n",
    "    # \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-23 22:51:53 Starting - Starting the training job...\n",
      "2022-01-23 22:51:57 Starting - Launching requested ML instancesLossNotDecreasing: InProgress\n",
      "VanishingGradient: InProgress\n",
      "Overfit: InProgress\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: InProgress\n",
      "LowGPUUtilization: InProgress\n",
      "ProfilerReport: InProgress\n",
      "......\n",
      "2022-01-23 22:53:14 Starting - Preparing the instances for training.........\n",
      "2022-01-23 22:54:54 Downloading - Downloading input data...............\n",
      "2022-01-23 22:57:15 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-01-23 22:57:13,434 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-01-23 22:57:13,437 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-23 22:57:13,445 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-01-23 22:57:13,457 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-01-23 22:57:14,358 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-23 22:57:14,371 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-23 22:57:14,381 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-23 22:57:14,390 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 128,\n",
      "        \"lr\": \"0.0014267005122579185\",\n",
      "        \"epochs\": 3\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"bestmodel-2022-01-23-22-51-52-856\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-758745060942/bestmodel-2022-01-23-22-51-52-856/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_model\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_model.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":128,\"epochs\":3,\"lr\":\"0.0014267005122579185\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_model.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_model\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-758745060942/bestmodel-2022-01-23-22-51-52-856/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":3,\"lr\":\"0.0014267005122579185\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"bestmodel-2022-01-23-22-51-52-856\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-758745060942/bestmodel-2022-01-23-22-51-52-856/source/sourcedir.tar.gz\",\"module_name\":\"train_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_model.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"3\",\"--lr\",\"0.0014267005122579185\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.0014267005122579185\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=3\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_model.py --batch_size 128 --epochs 3 --lr 0.0014267005122579185\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:17.133 algo-1:29 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:17.802 algo-1:29 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.\u001b[0m\n",
      "\u001b[34mRunning on Device cpu\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:18.910 algo-1:29 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:18.912 algo-1:29 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:18.913 algo-1:29 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:18.914 algo-1:29 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:18.927 algo-1:29 INFO hook.py:591] name:fc.0.weight count_params:68096\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:18.927 algo-1:29 INFO hook.py:591] name:fc.0.bias count_params:133\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:18.927 algo-1:29 INFO hook.py:593] Total Trainable Params: 68229\u001b[0m\n",
      "\u001b[34mcreate data loaders\u001b[0m\n",
      "\u001b[34mtraining model\u001b[0m\n",
      "\u001b[34mEpoch 0, Phase train\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:21.130 algo-1:29 INFO hook.py:425] Monitoring the collections: gradients, losses, relu_input\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:21.132 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/prestepzero-*-start-1642978637803168.0_train-0-stepstart-1642978641131910.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:21.156 algo-1:29 INFO hook.py:488] Hook is writing from the hook with pid: 29\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:36.248 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-0-stepstart-1642978641143032.8_train-0-forwardpassend-1642978656247842.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:57:38.505 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-0-forwardpassend-1642978656251067.5_train-1-stepstart-1642978658505118.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:58:00.997 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-1-stepstart-1642978658513950.2_train-1-forwardpassend-1642978680996990.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:58:04.114 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-1-forwardpassend-1642978680999490.5_train-2-stepstart-1642978684114354.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:58:23.345 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-2-stepstart-1642978684119724.5_train-2-forwardpassend-1642978703345451.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:58:25.261 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-2-forwardpassend-1642978703347242.2_train-3-stepstart-1642978705260556.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:58:43.733 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-3-stepstart-1642978705267843.5_train-3-forwardpassend-1642978723733312.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:58:45.665 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-3-forwardpassend-1642978723735526.5_train-4-stepstart-1642978725665098.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:59:03.924 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-4-stepstart-1642978725672829.0_train-4-forwardpassend-1642978743924029.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:59:06.401 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-4-forwardpassend-1642978743925841.2_train-5-stepstart-1642978746400970.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:59:24.725 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-5-stepstart-1642978746404552.2_train-5-forwardpassend-1642978764724926.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:59:26.540 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-5-forwardpassend-1642978764726752.5_train-6-stepstart-1642978766538881.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:59:45.204 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-6-stepstart-1642978766543412.8_train-6-forwardpassend-1642978785204225.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 22:59:47.190 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-6-forwardpassend-1642978785206120.8_train-7-stepstart-1642978787189017.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 23:00:06.817 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-7-stepstart-1642978787193084.2_train-7-forwardpassend-1642978806817268.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 23:00:08.938 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-7-forwardpassend-1642978806819070.8_train-8-stepstart-1642978808937529.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 23:00:27.650 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-8-stepstart-1642978808941622.5_train-8-forwardpassend-1642978827650243.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 23:00:29.367 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-8-forwardpassend-1642978827652630.5_train-9-stepstart-1642978829362863.0/python_stats.\u001b[0m\n",
      "LossNotDecreasing: InProgress\n",
      "VanishingGradient: InProgress\n",
      "Overfit: InProgress\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: IssuesFound\n",
      "\u001b[34m[2022-01-23 23:00:48.240 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-9-stepstart-1642978829370406.2_train-9-forwardpassend-1642978848239609.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-23 23:00:50.054 algo-1:29 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/29-algo-1/train-9-forwardpassend-1642978848241556.0_train-10-stepstart-1642978850053635.2/python_stats.\u001b[0m\n",
      "LossNotDecreasing: InProgress\n",
      "VanishingGradient: Error\n",
      "Overfit: InProgress\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: IssuesFound\n",
      "\u001b[34mEpoch 0, Phase valid\u001b[0m\n",
      "\u001b[34mEpoch 1, Phase train\u001b[0m\n",
      "\u001b[34mEpoch 1, Phase valid\u001b[0m\n",
      "\u001b[34mEpoch 2, Phase train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"training\": 's3://lesson4project/imageproject/'}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL MODEL LOCATION, save it here \n",
    "model_location=estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot a debugging output.\n",
    "job_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEGGING OUTPUTS\n",
    "# plot debuggin outputs\n",
    "from smdebug.trials import create_trial\n",
    "from smdebug.core.modes import ModeKeys\n",
    "\n",
    "trial = create_trial(estimator.latest_job_debugger_artifacts_path())\n",
    "#Fetch tensor names and print their lengths\n",
    "trial.tensor_names()\n",
    "len(trial.tensor(\"nll_loss_output_0\").steps(mode=ModeKeys.TRAIN))\n",
    "len(trial.tensor(\"nll_loss_output_0\").steps(mode=ModeKeys.EVAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up functions to plot the output tensors\n",
    "def get_data(trial, tname, mode):\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps(mode=mode)\n",
    "    vals = []\n",
    "    for s in steps:\n",
    "        vals.append(tensor.value(s, mode=mode))\n",
    "    return steps, vals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "\n",
    "\n",
    "def plot_tensor(trial, tensor_name):\n",
    "\n",
    "    steps_train, vals_train = get_data(trial, tensor_name, mode=ModeKeys.TRAIN)\n",
    "    print(\"loaded TRAIN data\")\n",
    "    steps_eval, vals_eval = get_data(trial, tensor_name, mode=ModeKeys.EVAL)\n",
    "    print(\"loaded EVAL data\")\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    host = host_subplot(111)\n",
    "\n",
    "    par = host.twiny()\n",
    "\n",
    "    host.set_xlabel(\"Steps (TRAIN)\")\n",
    "    par.set_xlabel(\"Steps (EVAL)\")\n",
    "    host.set_ylabel(tensor_name)\n",
    "\n",
    "    (p1,) = host.plot(steps_train, vals_train, label=tensor_name)\n",
    "    print(\"completed TRAIN plot\")\n",
    "    (p2,) = par.plot(steps_eval, vals_eval, label=\"val_\" + tensor_name)\n",
    "    print(\"completed EVAL plot\")\n",
    "    leg = plt.legend()\n",
    "\n",
    "    host.xaxis.get_label().set_color(p1.get_color())\n",
    "    leg.texts[0].set_color(p1.get_color())\n",
    "\n",
    "    par.xaxis.get_label().set_color(p2.get_color())\n",
    "    leg.texts[1].set_color(p2.get_color())\n",
    "\n",
    "    plt.ylabel(tensor_name)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_tensor(trial, \"nll_loss_output_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "print(f\"Training jobname: {training_job_name}\")\n",
    "print(f\"Region: {region}\")\n",
    "\n",
    "\n",
    "\n",
    "# get the training job object using the training job name and display the system metrics. \n",
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "\n",
    "tj = TrainingJob(training_job_name, region)\n",
    "tj.wait_for_sys_profiling_data_to_be_available()\n",
    "\n",
    "from smdebug.profiler.analysis.notebook_utils.timeline_charts import TimelineCharts\n",
    "\n",
    "system_metrics_reader = tj.get_systems_metrics_reader()\n",
    "system_metrics_reader.refresh_event_file_list()\n",
    "\n",
    "view_timeline_charts = TimelineCharts(\n",
    "    system_metrics_reader,\n",
    "    framework_metrics_reader=None,\n",
    "    select_dimensions=[\"CPU\", \"GPU\"],\n",
    "    select_events=[\"total\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROFILER REPORT\n",
    "#The profiler report will be saved in an S3 bucket.\n",
    "# Below we can see how to get the path of the report, fetch it and display it. \n",
    "\n",
    "rule_output_path = estimator.output_path + estimator.latest_training_job.job_name + \"/rule-output\"\n",
    "\n",
    "! aws s3 ls {rule_output_path} --recursive\n",
    "\n",
    "! aws s3 cp {rule_output_path} ./ --recursive\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# get the autogenerated folder name of profiler report\n",
    "profiler_report_name = [\n",
    "    rule[\"RuleConfigurationName\"]\n",
    "    for rule in estimator.latest_training_job.rule_job_summary()\n",
    "    if \"Profiler\" in rule[\"RuleConfigurationName\"]\n",
    "][0]\n",
    "\n",
    "import IPython\n",
    "\n",
    "IPython.display.HTML(filename=profiler_report_name + \"/profiler-output/profiler-report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "# You can also configure a sagemaker role and reference it by its name.\n",
    "# role = \"CustomSageMakerRoleName\"\n",
    "pytorch_model = PyTorchModel(model_data='s3://pytorch-sagemaker-example/model.tar.gz',\n",
    "                             role=role,\n",
    "                             entry_point='inference.py', \n",
    "                             framework_version=\"1.8\")\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type='ml.t2.medium', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint\n",
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.t2.medium\")\n",
    "# TODO: Add your deployment configuration like instance type and number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run an prediction on the endpoint\n",
    "image = {\"url\":\"https://example.com/predict.png\"} \n",
    "# TODO: Your code to load and preprocess image to send to endpoint for prediction\n",
    "response = predictor.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOURCE HELP FROM:\n",
    "    https://samuelabiodun.medium.com/how-to-deploy-a-pytorch-model-on-sagemaker-aa9a38a277b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
